<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      stf &bull; out &middot; KB with instant search
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/stfclv.github.io/public/css/poole.css">
  <link rel="stylesheet" href="/stfclv.github.io/public/css/syntax.css">
  <link rel="stylesheet" href="/stfclv.github.io/public/css/hyde.css">
  <link rel="stylesheet" href="/stfclv.github.io/public/css/algolia.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/stfclv.github.io/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/stfclv.github.io/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body class="theme-base-08">

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/stfclv.github.io/">
          stf &bull; out
        </a>
      </h1>
      <p class="lead">My personal knowledge base, blog notes and thoughts on top of the popular <a href="http://hyde.getpoole.com/" target="_blank">Hyde</a> &hearts; <a href="http://jekyllrb.com" target="_blank">Jekyll</a>. Made by <a href="https://twitter.com/stefun_" target="_blank">@stefun_</a>, Solutions Architect <a href="http://www.cloudera.com" target="_blank">@Cloudera</a>.</a></p>
    </div>

    <input type="text" class="algolia__input js-algolia__input" autocomplete="off" name="query" placeholder="Search in this site..." />

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/stfclv.github.io/">Home</a>

      

      
      
        
          
        
      
        
          
          <a class="sidebar-nav-item" href="/stfclv.github.io/about/">About</a>
          
        
      
        
      
        
          
        
      
        
          
          <a class="sidebar-nav-item" href="/stfclv.github.io/security/">Security</a>
          
        
      
        
          
          <a class="sidebar-nav-item" href="/stfclv.github.io/tricks/">Trixx</a>
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      

      <a class="sidebar-nav-item" href="https://github.com/stfclv/stfclv.github.io">GitHub project</a>
      <span class="sidebar-nav-item">Currently v2.1.0</span>
    </nav>

    <p>&copy; 2018. All rights reserved. Original by <a href="https://twitter.com/mdo" target="_blank">@mdo</a> and <a href="https://www.algolia.com/" target="_blank">Algolia</a>.</p>
  </div>
</div>


    <div class="content container">
      <div class="algolia__initial-content js-algolia__initial-content"><div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/stfclv.github.io/2014/03/14/added-asian-datacenter-offer/">
        Algolia Now Provides Realtime Search in Asia!
      </a>
    </h1>

    <span class="post-date">14 Mar 2014</span>

    <p><a href="http://blog.algolia.com/added-asian-%0Adatacenter-offer/screen-shot-2014-03-13-at-17-51-50/"><img src="/algoliasearch-jekyll-hyde/assets/Screen-Shot-2014-03-13-at-17.51.50-300x199.png" alt="New datacenter allows realtime search in Asia"></a></p>

<p>One of the terrific advantages of building a SaaS company is that your clients
can be anywhere in the world. We now have customers in more than 15 different
countries distributed across South America, Europe, Africa, and, of course,
North America. We feel incredibly lucky to have so many international
customers trusting us with their search.</p>

<p>Language support is one of the key factors that enabled us to enter these
markets. Since the beginning, we wanted to support every language used on the
Internet. To back our vision with action, we developed a very good support of
Asian languages over time. As an example, we are able to automatically
retrieve results in Traditional Chinese when the query is in Simplified
Chinese (or vice-versa). You simply need to add objects in Chinese, Japanese
or Korean, and we handle the language processing for you.</p>

<p>Despite the fact that we could process Asian languages well, we didn&#39;t plan to
open an Asian datacenter so early, mainly because we thought the API as a
service market was less mature in Asia than in the US or Europe. But we were
surprised when an article on <a href="http://www.36kr.com/p/209747.html">36kr.com</a>
gave us dozen of signups from China. We got more signups from China in the
past month than from Canada!</p>

<p>One of our core values is the speed of our search engine. To provide a
realtime search experience, we want the response times to be lower than 100ms,
including the round trip to search servers. In this context a low latency is
essential. Up to now we have been able to cover North America and Europe in
less than 100ms (search computation included) but our latency with Asia was
between 200ms and 300ms.</p>

<p>The first step of our on-boarding process is to select the datacenter where
your search engine is hosted (we offer multi-datacenter distribution only for
enterprise users). Interestingly, we discovered that we had no drop for
European &amp; US users but it became significant for others. It was a difficult
choice for people outside of these two regions, or even between the two
datacenters. So we also now display the latency from your browser and pre-
select the &quot;closest&quot; datacenter.</p>

<p>To propose better latency and to reduce friction in the on-boarding process,
it was clear that we had to add a datacenter in Asia. We chose Singapore for
its central location. Unfortunately, the hosting market is very different in
Asia. It&#39;s much more expensive to rent servers, so we sadly had to add a
premium on plan prices when choosing this datacenter.</p>

<p>We are very happy to open this new datacenter in Asia with a latency that
reaches our quality standard. Now that Algolia provides realtime search in
Asia, we are even happier to be able to help multinational websites and apps
provide a great search experience to all their users across Europe, North
America &amp; Asia in less than 100ms with our multi-datacenter support!*</p>

<p><em>Multi-datacenter support is currently only available for Enterprise
accounts.</em></p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/stfclv.github.io/2014/02/10/mongodb-and-sql-connectors/">
        Introducing Easier Onboarding and Activation with Connectors
      </a>
    </h1>

    <span class="post-date">10 Feb 2014</span>

    <p>Most of our users are <strong>technical</strong>. They love writing code, and we love
providing API clients in the major programming languages to them (we are
currently <a href="http://www.algolia.com/doc/apiclients)">supporting 10 platforms</a>.</p>

<p>They are doers. They love prototyping. Just like us, they work for startups
which need to move fast, and get things done, keeping in mind that done is
better than perfect. It is very important that they <strong>don&#39;t want to waste
time</strong>. In this post, I will explain how one would have used our API up to
now, and how we introduced SQL and MongoDB connectors for easier onboarding,
integration and testing.</p>

<h2>Before: The first steps with our API</h2>

<p>Up until now, our onboarding process asked you to try the API by uploading
your data. We emphasized our <a href="http://www.algolia.com/doc">documentation</a>, and
we made sure our users would not need more than a few minutes to integrate our
<a href="http://www.algolia.com/doc/rest">REST API</a>. Nevertheless, exporting your
application&#39;s data to a JSON or CSV file is often more complex than it
appears, especially when you have millions of rows - and especially because
developers are lazy :) No worries, that&#39;s <a href="http://www.codinghorror.com/blog/2005/08/how-to-be-lazy-dumb-and-successful.html">totally
OK</a>. It is something you may not be willing to do, especially
just to try a service, so we decided to try something else.</p>

<h3>Initial import</h3>

<p>90% of our users are using a SQL or MongoDB database. Exporting a table or a
collection to a JSON file can be easy if you&#39;re using a framework, for example
Ruby on Rails:</p>
<div class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span></span><span class="no">File</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;/tmp/export.json&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">f</span><span class="o">|</span>
  <span class="n">f</span> <span class="o">&lt;&lt;</span> <span class="no">MyActiveRecordModel</span><span class="o">.</span><span class="n">all</span><span class="o">.</span><span class="n">to_json</span>
<span class="k">end</span>
</code></pre></div>
<p>...or more annoying, for example when using PHP without any framework:</p>
<div class="highlight"><pre><code class="language-php" data-lang="php"><span></span><span class="x">mysql_connect(&#39;localhost&#39;, &#39;mysql_user&#39;, &#39;mysql_password&#39;);</span>
<span class="x">mysql_set_charset(&#39;utf8&#39;);</span>
<span class="x">$results = array();</span>
<span class="x">$q = mysql_query(&quot;SELECT * FROM YourTable&quot;);</span>
<span class="x">if ($q) {</span>
<span class="x">  while (($row = mysql_fetch_assoc($q))) {</span>
<span class="x">    array_push($results, $row);</span>
<span class="x">  }</span>
<span class="x">}</span>
<span class="x">$fp = fopen(&#39;/tmp/export.json&#39;, &#39;w&#39;);</span>
<span class="x">fwrite($fp, json_encode($results));</span>
<span class="x">fclose($fp);</span>
</code></pre></div>
<p>Anyway, in both cases it gets harder if you want to export millions of rows
without consuming hundreds GB of RAM. So you will need to use our API clients:</p>
<div class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span></span><span class="n">index</span> <span class="o">=</span> <span class="no">Algolia</span><span class="o">::</span><span class="no">Index</span><span class="o">.</span><span class="n">new</span> <span class="s2">&quot;YourIndex&quot;</span>
<span class="no">MyActiveRecordModel</span><span class="o">.</span><span class="n">find_in_batches</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">objects</span><span class="o">|</span>
  <span class="n">index</span><span class="o">.</span><span class="n">add_objects</span><span class="p">(</span><span class="n">objects</span><span class="p">)</span>
<span class="k">end</span>
<span class="c1"># that&#39;s actually what `MyActiveRecordModel.reindex!` does</span>

<span class="n">mysql_connect</span><span class="p">(</span><span class="s1">&#39;localhost&#39;</span><span class="p">,</span> <span class="s1">&#39;mysql_user&#39;</span><span class="p">,</span> <span class="s1">&#39;mysql_password&#39;</span><span class="p">);</span>
<span class="n">mysql_set_charset</span><span class="p">(</span><span class="s1">&#39;utf8&#39;</span><span class="p">);</span>
<span class="vg">$limit</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">;</span>
<span class="vg">$start</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="vg">$index</span> <span class="o">=</span> <span class="vg">$client</span><span class="o">-&gt;</span><span class="n">initIndex</span><span class="p">(</span><span class="s1">&#39;YourIndexName&#39;</span><span class="p">);</span>
<span class="k">while</span> <span class="p">(</span><span class="kp">true</span><span class="p">)</span> <span class="p">{</span>
  <span class="vg">$q</span> <span class="o">=</span> <span class="n">mysql_query</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM YourTable LIMIT &quot;</span> <span class="o">.</span> <span class="vg">$start</span> <span class="o">.</span> <span class="s2">&quot;,&quot;</span> <span class="o">.</span> <span class="vg">$limit</span><span class="p">);</span>
  <span class="vg">$n</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">if</span> <span class="p">(</span><span class="vg">$q</span><span class="p">)</span> <span class="p">{</span>
    <span class="vg">$objects</span> <span class="o">=</span> <span class="n">array</span><span class="p">();</span>
    <span class="k">while</span><span class="p">((</span><span class="vg">$row</span> <span class="o">=</span> <span class="n">mysql_fetch_assoc</span><span class="p">(</span><span class="vg">$q</span><span class="p">)))</span> <span class="p">{</span>
      <span class="n">array_push</span><span class="p">(</span><span class="vg">$objects</span><span class="p">,</span> <span class="vg">$row</span><span class="p">);</span>
      <span class="o">++</span><span class="vg">$n</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="vg">$index</span><span class="o">-&gt;</span><span class="n">addObjects</span><span class="p">(</span><span class="vg">$objects</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="k">if</span> <span class="p">(</span><span class="vg">$n</span> <span class="o">!=</span> <span class="vg">$limit</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">break</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="vg">$start</span> <span class="o">+=</span> <span class="vg">$n</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>
<h3>Incremental updates</h3>

<p>Once imported, you will need to go further and keep your DB and our indexes
up-to-date. You can either:</p>

<ul>
<li>Clear your index and re-import all your records hourly/daily with the previous methods: 

<ul>
<li>non-intrusive,</li>
<li>not real-time,</li>
<li>not durable,</li>
<li>need to import your data to a temporary index + replace the original one atomically once imported if you want to keep your service running while re-importing</li>
</ul></li>
</ul>

<p>Or</p>

<ul>
<li>Patch your application/website code to replicate every add/delete/update operations to our API: 

<ul>
<li>real-time,</li>
<li>consistent &amp; durable,</li>
<li>a little intrusive to some people, even though it is only a few lines of code (<a href="http://www.algolia.com/doc)">see our documentation</a></li>
</ul></li>
</ul>

<h2>After: Introducing connectors</h2>

<p>Even if we did recommend you to modify your application code to replicate all
add/delete/update operations from your DB to our API, this should not be the
only option, especially to test Algolia. Users want to be convinced before
modifying anything in their production-ready application/website. This is why
we are really proud to release 2 open-source connectors: a non-intrusive and
efficient way to synchronize your current SQL or MongoDB database with our
servers.</p>

<h3>SQL connector</h3>

<p>Github project: <a href="https://github.com/algolia/jdbc-java-connector">algolia/jdbc-java-connector</a> (MIT license, we love pull-requests :))</p>

<p>The connector starts by enumerating the table and push all matching rows to
our server. If you store the last modification date of a row in a field, you
can use it in order to send all detected updates every 10 seconds. Every 5
minutes, the connector synchronizes your database with the index by adding the
new rows and removing the deleted ones.</p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span></span><span class="n">jdbc</span><span class="o">-</span><span class="n">connector</span><span class="o">.</span><span class="na">sh</span> <span class="o">--</span><span class="n">source</span> <span class="s">&quot;jdbc:mysql://localhost/YourDB&quot;</span>  
  <span class="o">--</span><span class="n">username</span> <span class="n">mysqlUser</span> <span class="o">--</span><span class="n">password</span> <span class="n">mysqlPassword</span>             
  <span class="o">--</span><span class="n">selectQuery</span> <span class="s">&quot;SELECT * FROM YourTable&quot;</span> <span class="o">--</span><span class="n">primaryField</span> <span class="n">id</span> 
  <span class="o">--</span><span class="n">updateQuery</span> <span class="s">&quot;SELECT * FROM YourTable WHERE updated_at &gt; _$&quot;</span>
  <span class="o">--</span><span class="n">updatedAtField</span> <span class="n">updated_at</span> 
  <span class="o">--</span><span class="n">applicationId</span> <span class="n">YourApplicationId</span> <span class="o">--</span><span class="n">apiKey</span> <span class="n">YourApiKey</span> <span class="o">--</span><span class="n">index</span> <span class="n">YourIndexName</span>
</code></pre></div>
<p>If you don&#39;t have an updated_at  field, you can use:</p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span></span><span class="n">jdbc</span><span class="o">-</span><span class="n">connector</span><span class="o">.</span><span class="na">sh</span> <span class="o">--</span><span class="n">source</span> <span class="s">&quot;jdbc:mysql://localhost/YourDB&quot;</span>  
  <span class="o">--</span><span class="n">username</span> <span class="n">mysqlUser</span> <span class="o">--</span><span class="n">password</span> <span class="n">mysqlPassword</span>             
  <span class="o">--</span><span class="n">selectQuery</span> <span class="s">&quot;SELECT * FROM YourTable&quot;</span> <span class="o">--</span><span class="n">primaryField</span> <span class="n">id</span> 
  <span class="o">--</span><span class="n">applicationId</span> <span class="n">YourApplicationId</span> <span class="o">--</span><span class="n">apiKey</span> <span class="n">YourApiKey</span> <span class="o">--</span><span class="n">index</span> <span class="n">YourIndexName</span>
</code></pre></div>
<p>The full list of features is available on <a href="https://github.com/algolia/jdbc-java-connector">Github</a> (remember, we ♥ feature and pull-requests)!</p>

<h3>MongoDB connector</h3>

<p>Github
project: <a href="https://github.com/algolia/mongo-connector">algolia/mongo-connector</a></p>

<p>This connector has been forked from <a href="https://github.com/10gen-labs/mongo-connector">10gen-lab&#39;s official
connector</a> and is based on
MongoDB&#39;s <a href="http://docs.mongodb.org/manual/core/replica-set-oplog/">operation logs</a>. This means you will need to start your mongod  server specifying a
<a href="http://docs.mongodb.org/manual/tutorial/deploy-replica-set/">replica set</a>.
Basically, you need to start your server with: mongod --replSet
REPLICA<em>SET</em>IDENTIFIER. Once started, the connector will replicate each
addition/deletion/update to our server, sending a batch of operations every 10
seconds.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>mongo-connector -m localhost:27017 -n myDb.myCollection 
  -d ./doc_managers/algolia_doc_manager.py              
  -t YourApplicationID:YourApiKey:YourIndex
</code></pre></div>
<p>The full features list is available on <a href="https://github.com/algolia/mongo-connector">Github</a> (we ♥ feature and pull-requests).</p>

<h2>Conclusion: Easier Onboarding, Larger Audience!</h2>

<p>Helping our users to onboard and try Algolia without writing a single line of
code is not only a way to attract more non-technical users; It is also a way
to save the time of our technical but overbooked users, allowing them to be
convinced without wasting their time before really implementing it.</p>

<p>Those connectors are open-source and we will continue to improve them based on
your feedback. Your feature requests are welcome!</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/stfclv.github.io/2014/01/29/postmortem-todays-8min-indexing-downtime/">
        Postmortem of today's 8min indexing downtime
      </a>
    </h1>

    <span class="post-date">29 Jan 2014</span>

    <p>Today (Jan 29) at 9:30pm UTC, our service experienced an 8 minute partial
outage during which we have rejected many write operations sent to the
indexing API (exactly 2841 calls). We call it &quot;partial&quot; as all search queries
have been honored without any problem. For end-users, there was no visible
problem.</p>

<p>Transparency is in our DNA: this outage is visible on our status page
(<a href="http://status.algolia.com">status.algolia.com</a>) but we also wanted to share
with you all the details of the outage and more importantly the details of our
response.</p>

<h2>The alert</h2>

<p>This morning I fixed a rare bug in indexing complex hierarchical objects. This
fix successfully passed all the tests after development. We have 6000+ unit
tests and asserts, and 200+ non regression tests. So I felt confident when I
entered the deploy password in our automatic deployment script.</p>

<p>A few seconds after, I started to receive a lot of text messages on my
cellphone.</p>

<p>We developed several embedded probes to detect all kinds of problems and alert
us using Twilio and Hipchat APIs. They detect for example:</p>

<ul>
<li>a process that restart</li>
<li>an unusually long query</li>
<li>a write failure</li>
<li>a low memory warning</li>
<li>a low disk-free warning</li>
<li>etc.</li>
</ul>

<p>In case embedded probes can&#39;t run, other external probes run once a minute
from an independent datacenter (Google App Engine). These also automatically
update our status page when a problem impacts the quality of service.</p>

<p>Our indexing processes were crash looping. I immediately decided to rollback
to the previous version.</p>

<h2>The rollback</h2>

<p>Until today, our standard rollback process was to revert the commit, launch
the recompile and finally deploy. This is long, very long when your know that
you have an outage in production. The rollback took about 5 minutes in total
out of the 8 minutes.</p>

<h2>How we will avoid this situation in the future</h2>

<p>Even if the outage was on a relatively small period of time, we still believe
it was too long. To make sure this will not happen again:</p>

<ul>
<li>We have added a very fast rollback process in the way of a simple press button like the one we use to deploy. An automatic deploy is nice, but an automatic rollback is actually more critical when needed!</li>
<li>Starting now, we will deploy new versions of the service on clusters hosting community projects such as Hacker News Search or Twitter handle search, before pushing the update on clusters hosting paying customers. Having real traffic is key to detect some types of errors. Unit-tests &amp; non-regression tests cannot catch everything.</li>
<li>And of course we added non-regression tests for this specific error.</li>
</ul>

<h2>Conclusion</h2>

<p>Having all these probes in our infrastructure was key to detect today&#39;s
problem and react quickly. In real conditions, it proved not to be enough. In
a few hours we have implemented a much better way to handle this kind of
situation. The quality of our service is our top priority. Thank you for your
support!</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/stfclv.github.io/2014/01/24/hacker-news-search-algolia/">
        Hacker News search: 6.5 million articles and comments at your fingertips
      </a>
    </h1>

    <span class="post-date">24 Jan 2014</span>

    <p>We are <a href="https://news.ycombinator.com">Hacker News</a> readers and probably just
like you, there is not a day that goes by we don&#39;t use it. It is a little like
checking the weather app of the tech world. Long story short, Hacker News is
awesome, and we wanted to add our two cents to make it even greater to use.</p>

<p>Indeed, here is our problem: how do we instantly access the old posts we wish
we had saved?</p>

<h2>Powering a new Hacker News search engine</h2>

<p>Up until now we&#39;ve been using <a href="http://www.hnsearch.com">hnsearch.com</a>,
maintained for years by the great folks at <a href="http://octopart.com/">Octopart</a>. I
hope we speak on behalf of the HN community here, we are all grateful for the
work they put in hnsearch.com and they inspired us to pursue their effort.</p>

<p>Back in September 2013, we created a &quot;<a href="https://news.ycombinator.com/item?id=6476003">homemade Hacker News
crawler</a>&quot; and built a search
engine with the data we could get. It was not perfect but somehow, it did the
job fine.</p>

<p><a href="http://blog.ycombinator.com/algolia-%0Ayc-w14-launches-a-search-api-that-lets-you-provide-apple-spotlight-like-%0Arealtime-search-for-your-app-or-service">Now part of the Ycombinator W14 batch</a>, we have a direct access to the data
and it has allowed us to provide instant search for the entire content of
Hacker News, 1.2 million articles, 5.2 million comments as of today. See for
yourself right here: <a href="http://hn.algolia.com/">hn.algolia.com</a></p>

<h2>Here is how we did it</h2>

<ul>
<li><h3>Hacker News API access</h3>

<ul>
<li>YC provides us a private API access to fetch batches of 1000 items (an item being a comment or a post). Every two minutes, we update our database with the latest 1000 items. Last 48,000 items are refreshed every hour to keep the number of votes and comments up to date.</li>
</ul>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span># Yep, that&#39;s a Lisp API :)
EXPORT_REGEXP = %r{^((d+) (story|comment|poll|pollopt) &quot;(.+)&quot; (d+) (?:nil|&quot;(.*)&quot;) (?:nil|&quot;(.+)&quot;) (?:nil|&quot;(.*)&quot;) (?:nil|-?(d+)) (?:nil|(([d ]+))) (?:nil|(d+)))$}
</code></pre></div></li>
<li><h3>Thumbnails generation</h3>

<ul>
<li>We use <a href="https://code.google.com/p/wkhtmltopdf/">wkhtmltoimage</a> to render the URLs and generate the associated thumbnails. Playing with connection timeouts and JavaScript infinite loops was a pleasure:</li>
</ul>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>(timeout 60 xvfb-run --auto-servernum --server-args=&quot;-screen 0, 1024x768x24&quot; 
wkhtmltoimage-amd64 --height 768 --use-xserver--javascript-delay 30000 &quot;$URL&quot; &quot;$FILE&quot; || 
timeout 60 xvfb-run --auto-servernum --server-args=&quot;-screen 0, 1024x768x24&quot; 
wkhtmltoimage-amd64 --height 768 --use-xserver --disable-javascript &quot;$URL&quot; &quot;$FILE&quot;) &amp;&amp; 
convert &quot;$FILE&quot; -resize &#39;100!x100&#39; &quot;$FILE&quot;
</code></pre></div></li>
<li><h3>Thumbnails storage</h3>

<ul>
<li>Thumbnails are resized and stored on a S3 bucket.</li>
</ul>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>AWS::S3::S3Object.store(&quot;#{id}.png&quot;, open(temp_file), &#39;hnsearch&#39;, access: :public_read)
</code></pre></div></li>
<li><h3>Thumbnails distribution</h3>

<ul>
<li>We configured a CloudFront instance targeting the S3 bucket to distribute thumbnails with low latency and high data transfer speed. We followed Amazon&#39;s associated <a href="http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/MigrateS3ToCloudFront.html">developer guide</a>.</li>
</ul></li>
<li><h3>Indexing</h3>

<ul>
<li>We used the &quot;<a href="https://github.com/algolia/algoliasearch-rails">algoliasearch-rails</a>&quot; gem and a standard (Ruby on Rails) MySQL-backed ActiveRecord setup. Indexing is performed automatically as soon as new items are added to the database, providing a near-realtime experience.</li>
</ul></li>
<li><h3>Configuration</h3>
<div class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span></span><span class="k">class</span> <span class="nc">Item</span> <span class="o">&lt;</span> <span class="no">ActiveRecord</span><span class="o">::</span><span class="no">Base</span>
  <span class="kp">include</span> <span class="no">AlgoliaSearch</span>

  <span class="n">algoliasearch</span> <span class="ss">per_environment</span><span class="p">:</span> <span class="kp">true</span> <span class="k">do</span>
    <span class="c1"># the list of attributes sent to Algolia&#39;s API</span>
    <span class="n">attribute</span> <span class="ss">:created_at</span><span class="p">,</span> <span class="ss">:title</span><span class="p">,</span> <span class="ss">:url</span><span class="p">,</span> <span class="ss">:author</span><span class="p">,</span> <span class="ss">:points</span><span class="p">,</span> <span class="ss">:story_text</span><span class="p">,</span> <span class="ss">:comment_text</span><span class="p">,</span> <span class="ss">:author</span><span class="p">,</span> <span class="ss">:num_comments</span><span class="p">,</span> <span class="ss">:story_id</span><span class="p">,</span> <span class="ss">:story_title</span><span class="p">,</span> <span class="ss">:story_url</span>
    <span class="n">attribute</span> <span class="ss">:created_at_i</span> <span class="k">do</span>
      <span class="n">created_at</span><span class="o">.</span><span class="n">to_i</span>
    <span class="k">end</span>

    <span class="c1"># The order of the attributes sets their respective importance.</span>
    <span class="c1"># `title` is more important than `{story,comment}_text`, `{story,comment}_text` more than `url`, `url` more than `author`</span>
    <span class="c1"># btw, do not take into account position to avoid first word match boost</span>
    <span class="n">attributesToIndex</span> <span class="o">[</span><span class="s1">&#39;unordered(title)&#39;</span><span class="p">,</span> <span class="s1">&#39;unordered(story_text)&#39;</span><span class="p">,</span> <span class="s1">&#39;unordered(comment_text)&#39;</span><span class="p">,</span> <span class="s1">&#39;unordered(url)&#39;</span><span class="p">,</span> <span class="s1">&#39;author&#39;</span><span class="p">,</span> <span class="s1">&#39;created_at_i&#39;</span><span class="o">]</span>

    <span class="c1"># add tags used for filtering</span>
    <span class="n">tags</span> <span class="k">do</span>
      <span class="o">[</span><span class="n">item_type</span><span class="p">,</span> <span class="s2">&quot;author_</span><span class="si">#{</span><span class="n">author</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;story_</span><span class="si">#{</span><span class="n">story_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="o">]</span>
    <span class="k">end</span>

    <span class="c1"># Custom ranking allows to automatically sort the results by a custom criteria</span>
    <span class="c1"># in this case, a decreasing sort of the number of HN points and comments.</span>
    <span class="n">customRanking</span> <span class="o">[</span><span class="s1">&#39;desc(points)&#39;</span><span class="p">,</span> <span class="s1">&#39;desc(num_comments)&#39;</span><span class="o">]</span>

    <span class="c1"># controls the way results are sorted sorting on the following 4 criteria (one after another)</span>
    <span class="c1"># I removed the &#39;exact&#39; match critera (improve 1-words query relevance, doesn&#39;t fit HNSearch needs)</span>
    <span class="n">ranking</span> <span class="o">[</span><span class="s1">&#39;typo&#39;</span><span class="p">,</span> <span class="s1">&#39;proximity&#39;</span><span class="p">,</span> <span class="s1">&#39;attribute&#39;</span><span class="p">,</span> <span class="s1">&#39;custom&#39;</span><span class="o">]</span>

    <span class="c1"># google+, $1.5M raises, C#: we love you</span>
    <span class="n">separatorsToIndex</span> <span class="s1">&#39;+#$&#39;</span>
  <span class="k">end</span>

  <span class="k">def</span> <span class="nf">story_text</span>
    <span class="n">item_type_cd</span> <span class="o">!=</span> <span class="no">Item</span><span class="o">.</span><span class="n">comment</span> <span class="p">?</span> <span class="n">text</span> <span class="p">:</span> <span class="kp">nil</span>
  <span class="k">end</span>

  <span class="k">def</span> <span class="nf">story_title</span>
    <span class="n">comment?</span> <span class="o">&amp;&amp;</span> <span class="n">story</span> <span class="p">?</span> <span class="n">story</span><span class="o">.</span><span class="n">title</span> <span class="p">:</span> <span class="kp">nil</span>
  <span class="k">end</span>

  <span class="k">def</span> <span class="nf">story_url</span>
    <span class="n">comment?</span> <span class="o">&amp;&amp;</span> <span class="n">story</span> <span class="p">?</span> <span class="n">story</span><span class="o">.</span><span class="n">url</span> <span class="p">:</span> <span class="kp">nil</span>
  <span class="k">end</span>

  <span class="k">def</span> <span class="nf">comment_text</span>
    <span class="n">comment?</span> <span class="p">?</span> <span class="n">text</span> <span class="p">:</span> <span class="kp">nil</span>
  <span class="k">end</span>

  <span class="k">def</span> <span class="nf">comment?</span>
    <span class="n">item_type_cd</span> <span class="o">==</span> <span class="no">Item</span><span class="o">.</span><span class="n">comment</span>
  <span class="k">end</span>

  <span class="k">def</span> <span class="nf">num_comments</span>
    <span class="n">item_type_cd</span> <span class="o">==</span> <span class="no">Item</span><span class="o">.</span><span class="n">story</span> <span class="p">?</span> <span class="n">story_comments</span><span class="o">.</span><span class="n">count</span> <span class="p">:</span> <span class="kp">nil</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></li>
<li><h3>Search</h3>

<ul>
<li>Queries are sent directly to our API via the<a href="https://github.com/algolia/algoliasearch-client-js"> javascript client</a>, the javascript code uses a public API-Key that can only perform queries.</li>
</ul></li>
</ul>

<h2>Seeking feedback from the community</h2>

<p>There is still room for improvement and we would love to know how you are
searching for news on HN. What is important for you? Are you searching by
date, by upvote, by comment or by user? All together maybe?</p>

<p>We would love to have your feedback! Don&#39;t hesitate to checkout the code: <a href="https://github.com/algolia/hn-search">We
open-sourced it</a>.</p>

<p>Special thanks to the <a href="http://octopart.com/">Octopart</a> and
<a href="http://ycombinator.com/">YC</a> teams for making this experience possible!</p>

<p>Give it a try now: <a href="http://hn.algolia.com">hn.algolia.com</a></p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/stfclv.github.io/2014/01/18/search-grader-engine-performing/">
        Search Grader by Algolia: How does your search engine perform?
      </a>
    </h1>

    <span class="post-date">18 Jan 2014</span>

    <p><a href="http://grader.algolia.com"><img src="/algoliasearch-jekyll-hyde/assets/Capture-decran-2014-01-24-01.26.08-600x150.png" alt="algolia-search-grader"></a></p>

<h2>Search is important</h2>

<p>An effective search engine should be a seamless and natural extension of the
user experience. With improved relevance, your users should be able to find
what they are looking for in no time.</p>

<p>Unfortunately, developers often consider search as a second-tier priority.
This is a mistake. Every day, consumers use Google, Amazon, and Youtube to
find what they want on the web quickly and easily. Users of web applications
and eCommerce websites will feel the gap in search experience. As their
expectations are not met, your conversion rate will plummet, your bounce rate
will skyrocket, and the damage to your brand may be irredeemable.</p>

<h2>Search is tricky</h2>

<p>The reason why many web applications and e-commerce websites suffer from bad
search is because finding a good solution is not easy. Few current search
technologies combine relevancy and business metrics in a way that sorts search
results optimally.</p>

<p>In most cases, they fail on the following items:</p>

<ul>
<li>long response times,</li>
<li>no handling of mistakes,</li>
<li>no search field auto-completion,</li>
<li>unexplainable or even nonexistent results.</li>
</ul>

<p>To improve your search experience, you first need to understand which areas
are problematic. That&#39;s exactly why we built Search Grader by Algolia.</p>

<h2>Introducing Search Grader by Algolia</h2>

<p><a href="http://grader.algolia.com/">Search Grader</a> by Algolia is a tool to help you
quickly find out what your search engine may be missing. We divided the search
user experience in 3 categories in order to get a maximum score of 100:</p>

<ul>
<li>User Experience: 30 points</li>
<li>Speed: 20 points</li>
<li>Relevance: 50 points</li>
</ul>

<p><strong>User Experience: 30/100</strong></p>

<p>User experience is not just design, it&#39;s the key of a good user satisfaction.
If your users cannot find what they&#39;re searching for, they will just leave.</p>

<ul>
<li><strong>Searchbox visibility (3 pts)</strong>: It is easier for your users to find something if your search bar is clearly visible!</li>
<li><strong>Descriptive placeholder (2 pts) </strong>: A hint in your search bar is a good way to let your users know what kind of data they can dig into.</li>
<li><strong>Searchbox auto-completion (6 pts)</strong>: Auto-completion guides your users more efficiently towards what they are looking for.</li>
<li><strong>Suggestions after the first keystroke (5 pts)</strong>: Delight your users by providing relevant suggestions immediately after the first keystroke.</li>
<li><strong>Faceting (4 pts)</strong>: Faceting enables users to browse results by filtering them on specific categories (e.g., author, tags, price).</li>
<li><strong>Highlight (6 pts)</strong>: You need to explain why the displayed results are chosen, especially when you tolerate typos or misspelled queries.</li>
<li><strong>Pagination (2 pts)</strong>: Providing relevant results on the first page is great. But to keep your users engaged, you need to give them an easy way to access other results.</li>
<li><strong>Picture (2 pts):</strong> Sometime images are the fastest way to display information. Users will go through results and find the right hits much faster if you show them images.</li>
</ul>

<p><strong>Speed: 20/100</strong></p>

<p>If results show up in more than 200ms, you will lose part of your users. Time
is money, real-time is gold. Because your location is important to the speed
of the search we graded speed 3 times based on the location of the user:</p>

<ul>
<li>Response time from US East coast</li>
<li>Response time from US West coast</li>
<li>Response time from Europe</li>
</ul>

<p><strong>Relevance: 50/100</strong></p>

<p>Relevance is when you give your users what they want in the top results.
Although it&#39;s not very fancy, it&#39;s probably the more critical aspect of a good
search engine.</p>

<ul>
<li><strong>Typo-tolerance (10 pts)</strong>: People make a lot of typos, especially on mobile devices. Tolerating misspelled queries provides a great value to both your users and the products you promote.</li>
<li><strong>Auto-completion shows results, not queries (10 pts)</strong>: Suggesting queries is good. Suggesting results directly is a lot better as you spare your users one click and a lot of time.</li>
<li><strong>Ranking uses business metrics (10 pts)</strong>: Considering customized criteria such as sales numbers or the popularities in the way you rank results makes a key difference. It is THE way to give relevant results with one single keystroke.</li>
<li><strong>Overall ranking (20 pts)</strong>: Search must always return relevant results. We perform multiple queries to detect if your search is performing well.</li>
</ul>

<h2>Get Google, Amazon-like search for your website</h2>

<p>These criteria were defined by our team of experts with over 30+ years of
experience in search.</p>

<p>We tested out some of the biggest names in tech:</p>

<p><strong><a href="http://grader.algolia.com"><img src="/algoliasearch-jekyll-hyde/assets/Capture-decran-2014-01-17-18.22.23.png" alt="Algolia search grader"></a></strong></p>

<p>As you could expect, Amazon and LinkedIn received an excellent score of
90/100. That&#39;s the kind of quality Algolia can help you achieve in your
application or e-commerce website, for as low as
<a href="http://www.algolia.com/pricing/">$19/month</a>.</p>

<p>Now, how about your search? How is it performing? To find out, use <a href="http://grader.algolia.com/">Search
Grader</a> by Algolia.</p>

<p>If you want to share your ideas with us, please leave your comments!</p>

  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/stfclv.github.io/page8">Older</a>
  
  
    
      <a class="pagination-item newer" href="/stfclv.github.io/page6">Newer</a>
    
  
</div>
</div>

      <div class="algolia__search-content js-algolia__search-content">
        <h1 class="page-title">Search</h1>
        <div class="posts algolia__results"></div>
      </div>
    </div>

  <script>
  window.ALGOLIA_CONFIG = {
    'applicationId': 'Y467AE5IQA',
    'indexName': 'jekyll_stfclv.github.io',
    'apiKey': '',
    'baseurl': '/stfclv.github.io'
  }
</script>
<script id="algolia__template" type="text/template">

  <div class="algolia__result">
    <a class="algolia__result-link" href="{{ full_url }}#algolia:{{ css_selector }}">{{{ _highlightResult.title.value }}}</a>
    {{#posted_at}}
    <div class="algolia__result-date">{{ posted_at_readable }}</div>
    {{/posted_at}}
    <div class="algolia__result-text">{{{ _highlightResult.text.value }}}</div>
  </div>

</script>
<script id="algolia__template--no-results" type="text/template">
  No results found.
</script>
<script src="//cdn.jsdelivr.net/jquery/2.1.4/jquery.min.js"></script>
<script src="//cdn.jsdelivr.net/algoliasearch/3.6.0/algoliasearch.min.js"></script>
<script src="//cdn.jsdelivr.net/algoliasearch.helper/2.1.0/algoliasearch.helper.min.js"></script>
<script src="//cdn.jsdelivr.net/hogan.js/3.0.2/hogan.min.js"></script>
<script src="//cdn.jsdelivr.net/momentjs/2.10.3/moment.min.js"></script>
<script src="/stfclv.github.io/public/js/algolia.js"></script>

  </body>
</html>
